# Binomial Process & Poisson Process: อธิบายเจาะลึกพร้อมตัวอย่าง

---

## ส่วนที่ 1: Binomial Process

---

### 1.1 จุดเริ่มต้น — Bernoulli Trial

ก่อนเข้าใจ Binomial Process ต้องเข้าใจ **Bernoulli Trial** ก่อน

Bernoulli Trial คือการทดลองที่มีผลลัพธ์ได้เพียง 2 แบบ:
- **Success** (สำเร็จ) ด้วยความน่าจะเป็น **p**
- **Failure** (ล้มเหลว) ด้วยความน่าจะเป็น **1 − p = q**

ตัวแปรสุ่ม Bernoulli:

$$X_i = \begin{cases} 1 & \text{ถ้าเกิด success (ความน่าจะเป็น } p) \\ 0 & \text{ถ้าเกิด failure (ความน่าจะเป็น } 1-p) \end{cases}$$

**ตัวอย่าง Bernoulli Trial ในชีวิตจริง:**

| สถานการณ์ | Success | Failure | p |
|-----------|---------|---------|---|
| โยนเหรียญ | หัว | ก้อย | 0.5 |
| ตรวจสินค้า | ของเสีย | ผ่าน | 0.02 |
| ยิงบาส | ลง | ไม่ลง | 0.45 |
| ส่ง email marketing | เปิดอ่าน | ไม่เปิด | 0.20 |
| ผู้ป่วยรับยา | หาย | ไม่หาย | 0.85 |
| กดโฆษณา | คลิก | ไม่คลิก | 0.03 |

---

### 1.2 จาก Bernoulli → Binomial Distribution

เมื่อทำ Bernoulli Trial ซ้ำ **n** ครั้งอย่างเป็นอิสระ แล้วนับจำนวน success:

$$N = X_1 + X_2 + X_3 + \cdots + X_n$$

$N$ จะมีการแจกแจงแบบ **Binomial(n, p)**

**สูตรความน่าจะเป็น (PMF):**

$$P(N = k) = \binom{n}{k} p^k (1-p)^{n-k}, \quad k = 0, 1, 2, \ldots, n$$

โดย $\binom{n}{k} = \frac{n!}{k!(n-k)!}$ คือจำนวนวิธีเลือก k ตัวจาก n ตัว

**ค่าคาดหวังและความแปรปรวน:**

$$E[N] = np, \qquad Var[N] = np(1-p)$$

---

### 1.3 จาก Binomial Distribution → Binomial Process

**Binomial Process** คือการมอง Binomial ในมิติของ **เวลา (discrete time)**

แทนที่จะมองว่า "ทำ n ครั้งแล้วนับ success" เรามองว่า:

> ในแต่ละหน่วยเวลา t = 1, 2, 3, ... เกิด Bernoulli Trial หนึ่งครั้ง
> แล้วเราติดตามจำนวน success สะสม N(t) ตลอดเวลา

**นิยาม:** ให้ $X_1, X_2, X_3, \ldots$ เป็นลำดับ i.i.d. Bernoulli(p)

$$N(t) = \sum_{i=1}^{t} X_i, \quad t = 1, 2, 3, \ldots$$

**คุณสมบัติของ Binomial Process:**

1. $N(0) = 0$
2. $N(t) \sim \text{Binomial}(t, p)$
3. **Independent Increments:** $N(t_2) - N(t_1)$ เป็นอิสระจาก $N(t_1) - N(t_0)$ เมื่อ $t_0 < t_1 < t_2$
4. **Stationary Increments:** $N(t+s) - N(t) \sim \text{Binomial}(s, p)$ ขึ้นกับ $s$ เท่านั้น ไม่ขึ้นกับ $t$
5. **Markov Property:** สถานะอนาคตขึ้นกับปัจจุบันเท่านั้น

---

### 1.4 ตัวอย่างละเอียด: Binomial Process

#### ตัวอย่าง A — สายการผลิต

**สถานการณ์:** โรงงานผลิตหลอดไฟ ตรวจสอบหลอดไฟทีละหลอดทุก 1 นาที
แต่ละหลอดมีโอกาสเป็นของเสีย p = 0.05 (5%)

```
กำหนด:  n = จำนวนหลอดที่ตรวจ,  p = 0.05
        N(n) = จำนวนของเสียสะสมจนถึงหลอดที่ n
```

**คำถาม 1:** ตรวจ 20 หลอด ความน่าจะเป็นที่พบของเสียพอดี 2 หลอด?

```
N(20) ~ Binomial(20, 0.05)

P(N = 2) = C(20, 2) × (0.05)² × (0.95)¹⁸
         = 190 × 0.0025 × 0.3972
         = 190 × 0.000993
         ≈ 0.1887 (ประมาณ 18.87%)
```

**คำถาม 2:** ตรวจ 20 หลอด ความน่าจะเป็นที่พบของเสียอย่างน้อย 1 หลอด?

```
P(N ≥ 1) = 1 − P(N = 0)
         = 1 − C(20, 0) × (0.05)⁰ × (0.95)²⁰
         = 1 − 1 × 1 × 0.3585
         = 1 − 0.3585
         ≈ 0.6415 (ประมาณ 64.15%)
```

**คำถาม 3:** ค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานของจำนวนของเสียใน 100 หลอด?

```
E[N(100)] = 100 × 0.05 = 5 หลอด
Var[N(100)] = 100 × 0.05 × 0.95 = 4.75
SD[N(100)] = √4.75 ≈ 2.18 หลอด
```

**คำถาม 4:** ติดตาม N(t) ตลอดเวลา — ลำดับเหตุการณ์ตัวอย่าง

```
หลอดที่:  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20
ผล:       ✓  ✓  ✓  ✗  ✓  ✓  ✓  ✓  ✓  ✓   ✗   ✓   ✓   ✓   ✓   ✓   ✓   ✗   ✓   ✓
N(t):     0  0  0  1  1  1  1  1  1  1   2   2   2   2   2   2   2   3   3   3

(✓ = ผ่าน,  ✗ = ของเสีย)
```

กราฟ N(t) จะเป็นขั้นบันไดที่กระโดดขึ้น 1 ทุกครั้งที่เจอของเสีย

---

#### ตัวอย่าง B — Basketball Free Throws

**สถานการณ์:** นักบาสเกตบอลยิง free throw ได้เฉลี่ย 80% (p = 0.8)

**คำถาม:** ยิง 10 ลูก ความน่าจะเป็นที่ลงอย่างน้อย 8 ลูก?

```
N(10) ~ Binomial(10, 0.8)

P(N ≥ 8) = P(N=8) + P(N=9) + P(N=10)

P(N=8)  = C(10,8) × (0.8)⁸ × (0.2)²
        = 45 × 0.16777 × 0.04
        = 45 × 0.006711
        ≈ 0.3020

P(N=9)  = C(10,9) × (0.8)⁹ × (0.2)¹
        = 10 × 0.13422 × 0.2
        ≈ 0.2684

P(N=10) = C(10,10) × (0.8)¹⁰ × (0.2)⁰
        = 1 × 0.10737
        ≈ 0.1074

P(N ≥ 8) ≈ 0.3020 + 0.2684 + 0.1074 = 0.6778 (ประมาณ 67.78%)
```

---

#### ตัวอย่าง C — A/B Testing (Digital Marketing)

**สถานการณ์:** เว็บไซต์ทดสอบปุ่ม "สมัครสมาชิก" 2 แบบ

- **แบบ A (สีแดง):** CTR = 3% → p_A = 0.03
- **แบบ B (สีเขียว):** CTR = 5% → p_B = 0.05

ผู้เข้าชมแบบละ 200 คน

```
จำนวนคลิกแบบ A: N_A ~ Binomial(200, 0.03)
  E[N_A] = 200 × 0.03 = 6 คลิก
  SD[N_A] = √(200 × 0.03 × 0.97) ≈ 2.41

จำนวนคลิกแบบ B: N_B ~ Binomial(200, 0.05)
  E[N_B] = 200 × 0.05 = 10 คลิก
  SD[N_B] = √(200 × 0.05 × 0.95) ≈ 3.08
```

ใช้ Binomial Process ติดตามจำนวนคลิกสะสมเทียบกัน เพื่อตัดสินใจว่าเมื่อไหร่ความแตกต่างมีนัยสำคัญทางสถิติ

---

### 1.5 เวลารอคอยใน Binomial Process

#### Geometric Distribution — เวลาจนถึง Success แรก

ถ้า T₁ = จำนวน trial จนกว่าจะเกิด success ครั้งแรก:

$$T_1 \sim \text{Geometric}(p)$$

$$P(T_1 = k) = (1-p)^{k-1} \cdot p, \quad k = 1, 2, 3, \ldots$$

$$E[T_1] = \frac{1}{p}, \qquad Var[T_1] = \frac{1-p}{p^2}$$

**ตัวอย่าง:** ทอยลูกเต๋า (p = 1/6 สำหรับแต้ม 6)
- E[T₁] = 1/(1/6) = 6 ครั้ง (เฉลี่ยต้องทอย 6 ครั้งจึงจะได้แต้ม 6)

#### Negative Binomial — เวลาจนถึง Success ครั้งที่ r

ถ้า $T_r$ = จำนวน trial จนกว่าจะเกิด success ครั้งที่ r:

$$T_r \sim \text{Negative Binomial}(r, p)$$

$$P(T_r = k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}, \quad k = r, r+1, r+2, \ldots$$

$$E[T_r] = \frac{r}{p}, \qquad Var[T_r] = \frac{r(1-p)}{p^2}$$

**ตัวอย่าง:** ต้องขายของได้ 3 ชิ้น (r = 3) โดยแต่ละคนที่เข้ามามีโอกาสซื้อ 20% (p = 0.2)
- E[T₃] = 3/0.2 = 15 คน (ต้องเจอลูกค้าเฉลี่ย 15 คนจึงจะขายได้ 3 ชิ้น)

---

### 1.6 สรุป Binomial Process ในภาพรวม

```
                    ┌─────────────────────────────────────┐
                    │         Binomial Process             │
                    │   X₁, X₂, X₃, ... ~ Bernoulli(p)   │
                    │       N(t) = X₁ + X₂ + ... + Xₜ    │
                    └─────────────┬───────────────────────┘
                                  │
              ┌───────────────────┼───────────────────────┐
              ▼                   ▼                       ▼
     จำนวน success          เวลาถึง success         เวลาถึง success
     ใน t ครั้ง              ครั้งแรก                ครั้งที่ r
     ─────────────          ────────────            ──────────────
     Binomial(t, p)         Geometric(p)           NegBinomial(r, p)
     E = tp                 E = 1/p                E = r/p
```

---

---

## ส่วนที่ 2: Poisson Process

---

### 2.1 แรงจูงใจ — ทำไมต้อง Poisson?

Binomial Process ทำงานได้ดีเมื่อเหตุการณ์เกิดใน **เวลาที่นับได้** (discrete time) เช่น ตรวจสินค้าทีละชิ้น

แต่ในชีวิตจริงหลายอย่างเกิดใน **เวลาต่อเนื่อง** (continuous time):
- ลูกค้าเข้าร้านได้ทุกวินาที ไม่ใช่ทุก 1 นาทีพอดี
- สายโทรศัพท์เข้ามาได้ตลอดเวลา
- อุบัติเหตุบนถนนเกิดขึ้นได้ทุกขณะ

**Poisson Process** คือคำตอบ — เป็น "Binomial Process เวอร์ชัน continuous time"

---

### 2.2 จาก Binomial สู่ Poisson — ขั้นตอนการลู่เข้า

ลองแบ่งช่วงเวลา [0, t] เป็น n ส่วนเล็กๆ แต่ละส่วนยาว Δt = t/n

ในแต่ละส่วนย่อย เหตุการณ์เกิด 1 ครั้งด้วยความน่าจะเป็น p = λΔt = λt/n

```
|--Δt--|--Δt--|--Δt--|--Δt--|--Δt--|--Δt--| ... |--Δt--|
0                                                       t
  n ช่วงเล็กๆ, แต่ละช่วง p = λt/n
```

จำนวนเหตุการณ์ ~ Binomial(n, λt/n)

เมื่อ n → ∞ (แบ่งละเอียดขึ้นเรื่อยๆ):

$$\lim_{n \to \infty} \binom{n}{k} \left(\frac{\lambda t}{n}\right)^k \left(1 - \frac{\lambda t}{n}\right)^{n-k} = \frac{(\lambda t)^k e^{-\lambda t}}{k!}$$

นี่คือ **Poisson Distribution** และกระบวนการที่เกิดขึ้นคือ **Poisson Process**

**พิสูจน์แบบง่าย (สำหรับ k = 0):**

$$P(N = 0) = \left(1 - \frac{\lambda t}{n}\right)^n \xrightarrow{n \to \infty} e^{-\lambda t} \quad \checkmark$$

---

### 2.3 นิยามอย่างเป็นทางการ

**Poisson Process** {N(t), t ≥ 0} ด้วยอัตรา λ > 0 นิยามโดย:

**นิยามแบบที่ 1 (Counting):**
1. N(0) = 0
2. Independent Increments
3. $N(t+s) - N(t) \sim \text{Poisson}(\lambda s)$ สำหรับทุก t, s ≥ 0

**นิยามแบบที่ 2 (Infinitesimal):**
ในช่วงเวลาสั้นๆ h → 0:
1. P(เกิด 1 เหตุการณ์ใน h) = λh + o(h)
2. P(เกิด ≥ 2 เหตุการณ์ใน h) = o(h)  ← "เกิดพร้อมกัน 2 เหตุการณ์แทบเป็นไปไม่ได้"
3. เหตุการณ์ในช่วงเวลาที่ไม่ทับซ้อนกันเป็นอิสระ

โดย o(h) หมายถึงฟังก์ชันที่ o(h)/h → 0 เมื่อ h → 0

**นิยามแบบที่ 3 (Inter-arrival):**
ให้ T₁, T₂, T₃, ... เป็นเวลาระหว่างเหตุการณ์ที่ต่อเนื่องกัน
ถ้า Tᵢ ~ i.i.d. Exponential(λ) แล้ว N(t) เป็น Poisson Process อัตรา λ

---

### 2.4 สูตรสำคัญทั้งหมด

#### Poisson Distribution — จำนวนเหตุการณ์

$$P(N(t) = k) = \frac{(\lambda t)^k e^{-\lambda t}}{k!}$$

| k | สูตร | ความหมาย |
|---|------|---------|
| 0 | $e^{-\lambda t}$ | ไม่เกิดเหตุการณ์เลย |
| 1 | $\lambda t \cdot e^{-\lambda t}$ | เกิดพอดี 1 ครั้ง |
| 2 | $\frac{(\lambda t)^2}{2} e^{-\lambda t}$ | เกิดพอดี 2 ครั้ง |

$$E[N(t)] = \lambda t, \qquad Var[N(t)] = \lambda t$$

**สังเกต:** ค่าคาดหวัง = ความแปรปรวน เสมอ (เอกลักษณ์ของ Poisson)

#### Exponential Distribution — เวลาระหว่างเหตุการณ์

$$f(t) = \lambda e^{-\lambda t}, \quad t \geq 0$$

$$P(T > t) = e^{-\lambda t}$$

$$E[T] = \frac{1}{\lambda}, \qquad Var[T] = \frac{1}{\lambda^2}$$

**คุณสมบัติ Memoryless:**

$$P(T > s + t \mid T > s) = P(T > t)$$

"ถ้ารอมาแล้ว s หน่วยเวลาแล้วยังไม่เกิด เวลาที่ต้องรอต่อก็ยังเหมือนเริ่มรอใหม่"

#### Gamma Distribution — เวลาจนถึงเหตุการณ์ที่ r

เวลาจนถึงเหตุการณ์ที่ r: $S_r = T_1 + T_2 + \cdots + T_r$

$$S_r \sim \text{Gamma}(r, \lambda)$$

$$f(t) = \frac{\lambda^r t^{r-1} e^{-\lambda t}}{(r-1)!}, \quad t \geq 0$$

$$E[S_r] = \frac{r}{\lambda}, \qquad Var[S_r] = \frac{r}{\lambda^2}$$

---

### 2.5 ตัวอย่างละเอียด: Poisson Process

#### ตัวอย่าง A — Call Center

**สถานการณ์:** Call center ได้รับสายเฉลี่ย λ = 30 สาย/ชั่วโมง (= 0.5 สาย/นาที)

**คำถาม 1:** ความน่าจะเป็นที่ไม่มีสายเข้ามาเลยใน 5 นาที?

```
λt = 0.5 × 5 = 2.5

P(N = 0) = e^(-2.5) = 0.0821 (ประมาณ 8.21%)
```

**คำถาม 2:** ความน่าจะเป็นที่มีสายเข้ามามากกว่า 3 สายใน 5 นาที?

```
P(N > 3) = 1 − P(N ≤ 3)
         = 1 − [P(0) + P(1) + P(2) + P(3)]

P(0) = e^(-2.5) = 0.0821
P(1) = 2.5 × e^(-2.5) = 0.2052
P(2) = (2.5²/2) × e^(-2.5) = 3.125 × 0.0821 = 0.2565
P(3) = (2.5³/6) × e^(-2.5) = 2.6042 × 0.0821 = 0.2138

P(N ≤ 3) = 0.0821 + 0.2052 + 0.2565 + 0.2138 = 0.7576
P(N > 3) = 1 − 0.7576 = 0.2424 (ประมาณ 24.24%)
```

**คำถาม 3:** เวลาเฉลี่ยระหว่างสายแต่ละสาย?

```
E[T] = 1/λ = 1/0.5 = 2 นาที
```

**คำถาม 4:** ความน่าจะเป็นที่ต้องรอนานกว่า 4 นาทีกว่าจะมีสายถัดไป?

```
P(T > 4) = e^(-0.5 × 4) = e^(-2) = 0.1353 (ประมาณ 13.53%)
```

**คำถาม 5 (Memoryless):** รอมาแล้ว 3 นาทียังไม่มีสาย ความน่าจะเป็นที่ต้องรอเพิ่มอีก 2 นาที?

```
P(T > 5 | T > 3) = P(T > 2)    ← Memoryless!
                 = e^(-0.5 × 2) 
                 = e^(-1) 
                 = 0.3679 (ประมาณ 36.79%)

*** ไม่ว่าจะรอมานานเท่าไหร่ โอกาสรอเพิ่มอีก 2 นาทีก็เท่าเดิมเสมอ ***
```

**คำถาม 6:** เวลาเฉลี่ยจนได้รับสายครบ 5 สาย?

```
S₅ ~ Gamma(5, 0.5)
E[S₅] = 5/0.5 = 10 นาที
SD[S₅] = √(5/0.25) = √20 ≈ 4.47 นาที
```

---

#### ตัวอย่าง B — ร้านอาหาร

**สถานการณ์:** ร้านอาหารมีลูกค้าเข้ามาเฉลี่ย λ = 20 กลุ่ม/ชั่วโมง ในช่วงเวลาเย็น

**คำถาม 1:** ใน 15 นาที คาดว่าจะมีลูกค้าเข้ามากี่กลุ่ม?

```
E[N(0.25)] = 20 × 0.25 = 5 กลุ่ม
```

**คำถาม 2:** ร้านมีที่นั่ง 8 โต๊ะว่างอยู่ ความน่าจะเป็นที่ลูกค้าเข้ามาเกิน 8 กลุ่มใน 15 นาที?

```
λt = 5

P(N > 8) = 1 − P(N ≤ 8)

คำนวณ P(N ≤ 8):
k:    0       1       2       3       4       5       6       7       8
P(k): 0.0067  0.0337  0.0842  0.1404  0.1755  0.1755  0.1462  0.1044  0.0653

P(N ≤ 8) = 0.9319
P(N > 8) = 1 − 0.9319 = 0.0681 (ประมาณ 6.81%)
```

ร้านมีโอกาสประมาณ 7% ที่จะไม่มีโต๊ะพอใน 15 นาที

---

#### ตัวอย่าง C — Website Traffic & Server Scaling

**สถานการณ์:** เว็บไซต์ e-commerce ได้รับ request เฉลี่ย λ = 200 ครั้ง/วินาที
เซิร์ฟเวอร์ 1 ตัวรับได้สูงสุด 50 requests/วินาที

**คำถาม 1:** ต้องใช้เซิร์ฟเวอร์กี่ตัวเพื่อให้รองรับได้ 99% ของเวลา?

```
N(1) ~ Poisson(200)

ใช้ Normal Approximation: N ≈ Normal(200, 200)
SD = √200 ≈ 14.14

P(N ≤ c) = 0.99
c = μ + z₀.₉₉ × σ = 200 + 2.326 × 14.14 ≈ 200 + 32.9 ≈ 233

จำนวนเซิร์ฟเวอร์ = ⌈233/50⌉ = 5 ตัว
```

**คำถาม 2:** ใน 1 มิลลิวินาที มีโอกาสเท่าไรที่ไม่มี request เลย?

```
λt = 200 × 0.001 = 0.2

P(N = 0) = e^(-0.2) = 0.8187 (ประมาณ 81.87%)
```

---

#### ตัวอย่าง D — ฟิสิกส์: การสลายกัมมันตรังสี

**สถานการณ์:** สาร Polonium-210 มีอัตราสลาย λ = 0.005 อะตอม/วินาที (สำหรับตัวอย่างเล็กๆ)

**คำถาม:** ใน 10 นาที ความน่าจะเป็นที่สลายไปพอดี 3 อะตอม?

```
λt = 0.005 × 600 = 3

P(N = 3) = (3³/3!) × e^(-3)
         = (27/6) × 0.0498
         = 4.5 × 0.0498
         ≈ 0.2240 (ประมาณ 22.40%)
```

---

### 2.6 คุณสมบัติพิเศษของ Poisson Process

#### Superposition (การรวม)

ถ้า N₁(t) ~ Poisson(λ₁) และ N₂(t) ~ Poisson(λ₂) เป็นอิสระกัน:

$$N₁(t) + N₂(t) \sim \text{Poisson}(\lambda_1 + \lambda_2)$$

**ตัวอย่าง:** ร้านมีลูกค้าเดินเข้าทางหน้า 15 คน/ชม. และทางหลัง 5 คน/ชม.
ลูกค้ารวม ~ Poisson(20 คน/ชม.)

#### Thinning (การแยก/กรอง)

ถ้า N(t) ~ Poisson(λ) และแต่ละเหตุการณ์ถูกจัดเป็นประเภท I ด้วยความน่าจะเป็น p (อิสระกัน):

$$N_I(t) \sim \text{Poisson}(\lambda p), \qquad N_{II}(t) \sim \text{Poisson}(\lambda(1-p))$$

และ N_I, N_II เป็นอิสระกัน!

**ตัวอย่าง:** สายโทรเข้า call center 30 สาย/ชม. โดย 60% เป็นเรื่องสอบถาม, 40% เป็นเรื่องร้องเรียน
- สาย "สอบถาม" ~ Poisson(18 สาย/ชม.)
- สาย "ร้องเรียน" ~ Poisson(12 สาย/ชม.)
- ทั้งสองเป็นอิสระต่อกัน!

#### Conditional Distribution of Arrival Times

ถ้ารู้ว่ามีเหตุการณ์เกิด n ครั้งในช่วง [0, t] แล้ว เวลาที่เหตุการณ์เกิดจะมีการแจกแจงเหมือน **Order Statistics** ของ Uniform(0, t) จำนวน n ตัว

**ตัวอย่าง:** ถ้ารู้ว่ามีลูกค้า 5 คนเข้าร้านในชั่วโมงแรก เวลาที่แต่ละคนเข้ามาจะเหมือนกับสุ่มจุด 5 จุดบนช่วง [0, 60 นาที] แบบ uniform แล้วเรียงลำดับ

---

### 2.7 Non-homogeneous Poisson Process (NHPP)

ในความเป็นจริง อัตราการเกิดเหตุการณ์มักไม่คงที่

**NHPP** ใช้ λ(t) ที่เปลี่ยนแปลงตามเวลา:

$$P(N(t+s) - N(t) = k) = \frac{[\Lambda(t, t+s)]^k \cdot e^{-\Lambda(t, t+s)}}{k!}$$

โดย $\Lambda(t_1, t_2) = \int_{t_1}^{t_2} \lambda(s) \, ds$

**ตัวอย่าง:** ร้านอาหารมีลูกค้า:
- 11:00-12:00 → λ = 10 กลุ่ม/ชม.
- 12:00-13:00 → λ = 30 กลุ่ม/ชม. (ช่วง rush)
- 13:00-14:00 → λ = 15 กลุ่ม/ชม.

จำนวนลูกค้ารวมตั้งแต่ 11:00-14:00:

```
Λ = 10 + 30 + 15 = 55

N(3 ชม.) ~ Poisson(55)
E[N] = 55 กลุ่ม
```

---

## ส่วนที่ 3: เปรียบเทียบ Binomial vs Poisson อย่างละเอียด

---

### 3.1 ตารางเปรียบเทียบครบทุกมิติ

| มิติ | Binomial Process | Poisson Process |
|------|-----------------|----------------|
| **เวลา** | Discrete (t = 1, 2, 3, ...) | Continuous (t ≥ 0) |
| **พารามิเตอร์** | n (จำนวนครั้ง), p (ความน่าจะเป็น) | λ (อัตราต่อหน่วยเวลา) |
| **จำนวนเหตุการณ์สูงสุด** | มีขอบเขต (≤ n) | ไม่มีขอบเขต (0, 1, 2, ..., ∞) |
| **การแจกแจงจำนวนเหตุการณ์** | Binomial(n, p) | Poisson(λt) |
| **ค่าคาดหวัง** | np | λt |
| **ความแปรปรวน** | np(1−p) < np | λt = ค่าคาดหวัง |
| **เวลาจนถึงเหตุการณ์แรก** | Geometric(p) — discrete | Exponential(λ) — continuous |
| **เวลาจนถึงเหตุการณ์ที่ r** | Negative Binomial(r, p) | Gamma(r, λ) |
| **Memoryless** | ✗ (Geometric มี memoryless ในเวลา discrete) | ✓ (Exponential มี memoryless ในเวลา continuous) |
| **ใช้เมื่อ** | ทราบจำนวนครั้งที่ทำ (n คงที่) | ทราบอัตราการเกิด (λ คงที่) |

### 3.2 ความสัมพันธ์: Binomial ≈ Poisson

**กฎหัวแม่มือ:** ใช้ Poisson ประมาณ Binomial ได้เมื่อ:
- n ≥ 20
- p ≤ 0.05
- np ≤ 10

ตั้ง λ = np

**ตัวอย่างเปรียบเทียบตัวเลข:** n = 100, p = 0.02, λ = np = 2

| k | Binomial(100, 0.02) | Poisson(2) | ความต่าง |
|---|---------------------|-----------|---------|
| 0 | 0.1326 | 0.1353 | 0.0027 |
| 1 | 0.2707 | 0.2707 | 0.0000 |
| 2 | 0.2734 | 0.2707 | 0.0027 |
| 3 | 0.1823 | 0.1804 | 0.0019 |
| 4 | 0.0902 | 0.0902 | 0.0000 |
| 5 | 0.0353 | 0.0361 | 0.0008 |

ค่าใกล้เคียงกันมาก — Poisson เป็นตัวประมาณที่ดีเยี่ยม!

### 3.3 เลือกใช้อันไหน?

```
คำถามตัดสิน:

1. รู้จำนวนครั้งที่ทำ (n) แน่นอนไหม?
   ├── ใช่ → Binomial
   │   เช่น: ตรวจสินค้า 50 ชิ้น, ทอยเหรียญ 10 ครั้ง
   └── ไม่ → ไปข้อ 2

2. เหตุการณ์เกิดขึ้นในเวลาต่อเนื่องด้วยอัตราคงที่ไหม?
   ├── ใช่ → Poisson
   │   เช่น: ลูกค้าเข้าร้าน, สายโทรเข้า, อุบัติเหตุ
   └── ไม่ → พิจารณา Non-homogeneous Poisson หรือโมเดลอื่น

3. n ใหญ่มากและ p เล็กมาก?
   └── ใช้ Poisson ประมาณ Binomial ได้เลย (ง่ายกว่า)
```

---

## ส่วนที่ 4: กรณีศึกษาจากโลกจริง

---

### กรณีศึกษา 1: ออกแบบ Call Center

**โจทย์:** บริษัทประกันภัยต้องการออกแบบ call center ให้รองรับลูกค้าได้ 95% ของเวลา

**ข้อมูล:** สายเฉลี่ย 45 สาย/ชม., พนักงาน 1 คนรับได้ 6 สาย/ชม.

```
ใช้ Poisson Process: λ = 45 สาย/ชม.

ต้องหา c (จำนวนพนักงาน) ที่ capacity = 6c

หา N ที่ P(N(1) ≤ 6c) ≥ 0.95

N(1) ~ Poisson(45)
Normal Approximation: N ≈ Normal(45, 45), SD ≈ 6.71

P(N ≤ 6c) ≥ 0.95
6c ≥ 45 + 1.645 × 6.71 ≈ 45 + 11.04 ≈ 56.04

c ≥ 56.04/6 ≈ 9.34

ต้องใช้อย่างน้อย 10 คน
```

### กรณีศึกษา 2: Quality Control

**โจทย์:** โรงงานผลิต chip ล็อตละ 500 ชิ้น สุ่มตรวจ 50 ชิ้น ถ้าพบของเสีย ≤ 2 ชิ้นจึงยอมรับล็อต

**ข้อมูล:** อัตราของเสียจริง 3%

```
ใช้ Binomial: N ~ Binomial(50, 0.03), E[N] = 1.5

P(ยอมรับล็อต) = P(N ≤ 2)

P(0) = C(50,0)(0.03)⁰(0.97)⁵⁰ = 0.2181
P(1) = C(50,1)(0.03)¹(0.97)⁴⁹ = 0.3372
P(2) = C(50,2)(0.03)²(0.97)⁴⁸ = 0.2555

P(ยอมรับ) = 0.2181 + 0.3372 + 0.2555 = 0.8108

→ ล็อตที่มีของเสีย 3% จะถูกยอมรับประมาณ 81% ของเวลา
```

**เปรียบเทียบกับ Poisson Approximation:** λ = 50 × 0.03 = 1.5

```
P(0) = e^(-1.5) = 0.2231
P(1) = 1.5 × e^(-1.5) = 0.3347
P(2) = (1.5²/2) × e^(-1.5) = 0.2510

P(ยอมรับ) ≈ 0.2231 + 0.3347 + 0.2510 = 0.8088

ใกล้เคียงกับ Binomial (0.8108) มาก! ต่างแค่ 0.002
```

### กรณีศึกษา 3: ระบบ IT — Downtime Analysis

**โจทย์:** เซิร์ฟเวอร์ล่มเฉลี่ย 2 ครั้ง/เดือน ต้องการ SLA 99.9% uptime

```
ใช้ Poisson: λ = 2 ครั้ง/เดือน

เวลาเฉลี่ยระหว่างการล่ม (MTBF):
E[T] = 1/λ = 0.5 เดือน = 15 วัน

ความน่าจะเป็นที่ไม่ล่มเลยใน 1 เดือน:
P(N=0) = e^(-2) = 0.1353 (ประมาณ 13.53%)

เวลาเฉลี่ยจนล่มครบ 5 ครั้ง:
E[S₅] = 5/2 = 2.5 เดือน

→ ต้องปรับปรุงระบบเพื่อลด λ ลงอย่างมากจึงจะได้ 99.9% uptime
```

---

## สรุปท้าย

```
┌──────────────────────────────────────────────────────────────┐
│                    BINOMIAL PROCESS                          │
│  "ทำ n ครั้ง แต่ละครั้งสำเร็จด้วยความน่าจะเป็น p"          │
│                                                              │
│  ● Discrete Time                                             │
│  ● จำนวนจำกัด (≤ n)                                          │
│  ● Var < Mean (np(1-p) < np)                                 │
│  ● เวลารอ: Geometric → Negative Binomial                    │
│  ● ตัวอย่าง: QC sampling, A/B test, การทดลองทางคลินิก       │
└──────────────────────┬───────────────────────────────────────┘
                       │
                       │  n → ∞, p → 0, np = λ
                       │  (Poisson Limit Theorem)
                       ▼
┌──────────────────────────────────────────────────────────────┐
│                    POISSON PROCESS                            │
│  "เหตุการณ์เกิดแบบสุ่มด้วยอัตรา λ ต่อหน่วยเวลา"           │
│                                                              │
│  ● Continuous Time                                           │
│  ● ไม่มีขอบเขตบน                                            │
│  ● Var = Mean (λt = λt)                                      │
│  ● เวลารอ: Exponential → Gamma                              │
│  ● Memoryless                                                │
│  ● ตัวอย่าง: Call center, ER, server requests, กัมมันตรังสี  │
└──────────────────────────────────────────────────────────────┘
```

---

*เอกสารนี้อธิบาย Binomial Process และ Poisson Process อย่างละเอียด พร้อมตัวอย่างการคำนวณทุกขั้นตอน เหมาะสำหรับนักศึกษาและผู้ปฏิบัติงานที่ต้องใช้กระบวนการสุ่มในงานจริง*