# กระบวนการสุ่ม (Stochastic Processes): คู่มือฉบับละเอียด

## Markov Process, Counting Process, Binomial Process & Poisson Process

---

## 1. Markov Process (กระบวนการมาร์คอฟ)

### แนวคิดหลัก

Markov Process คือกระบวนการสุ่มที่มีคุณสมบัติ **"Memoryless"** หรือ **Markov Property** กล่าวคือ สถานะในอนาคตขึ้นอยู่กับสถานะปัจจุบันเท่านั้น ไม่ขึ้นกับว่าเราผ่านสถานะอะไรมาก่อนหน้านี้

ในทางคณิตศาสตร์:

$$P(X_{n+1} = j \mid X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j \mid X_n = i)$$

### องค์ประกอบสำคัญ

- **State Space (S):** เซตของสถานะทั้งหมดที่เป็นไปได้
- **Transition Probability:** ความน่าจะเป็นในการเปลี่ยนจากสถานะหนึ่งไปอีกสถานะหนึ่ง
- **Transition Matrix (P):** เมทริกซ์ที่รวบรวมค่า transition probability ทั้งหมด โดยแต่ละแถวรวมกันได้ 1

### ประเภทของ Markov Process

| ประเภท | State Space | Time |
|--------|------------|------|
| Discrete-Time Markov Chain (DTMC) | นับได้ (Discrete) | นับได้ (Discrete) |
| Continuous-Time Markov Chain (CTMC) | นับได้ (Discrete) | ต่อเนื่อง (Continuous) |
| Markov Process (ทั่วไป) | ต่อเนื่อง (Continuous) | ต่อเนื่อง (Continuous) |

### ตัวอย่าง: สภาพอากาศ

สมมติว่าสภาพอากาศมี 2 สถานะ: **แดด (S)** และ **ฝน (R)**

**Transition Matrix:**

|  | แดดพรุ่งนี้ | ฝนพรุ่งนี้ |
|---|---|---|
| **แดดวันนี้** | 0.7 | 0.3 |
| **ฝนวันนี้** | 0.4 | 0.6 |

**การคำนวณ:** ถ้าวันนี้อากาศแจ่มใส ความน่าจะเป็นที่อีก 2 วันจะเป็นฝน:

- วันที่ 1 แดด → วันที่ 2 แดด → วันที่ 3 ฝน: 0.7 × 0.3 = 0.21
- วันที่ 1 แดด → วันที่ 2 ฝน → วันที่ 3 ฝน: 0.3 × 0.6 = 0.18
- **รวม = 0.21 + 0.18 = 0.39**

หรือคำนวณด้วย P² แล้วดูค่าตำแหน่ง (S, R)

### ตัวอย่าง: การเคลื่อนที่ของลูกค้า (Customer Churn)

สถานะของลูกค้า: **Active (A)**, **Inactive (I)**, **Churned (C)**

```
Transition Matrix:
        A     I     C
  A [ 0.80  0.15  0.05 ]
  I [ 0.30  0.50  0.20 ]
  C [ 0.00  0.00  1.00 ]   ← Absorbing State (จากไปแล้วไม่กลับ)
```

**Steady-State Analysis:** เมื่อเวลาผ่านไปนานพอ สัดส่วนลูกค้าในแต่ละสถานะจะคงที่ หาได้จาก πP = π

### การประยุกต์ใช้จริง

- **PageRank ของ Google:** เว็บเพจเป็นสถานะ, ลิงก์เป็น transition
- **การเงิน:** Credit Rating Migration (AAA → AA → A → BBB → ...)
- **ชีววิทยา:** การกลายพันธุ์ของ DNA
- **NLP:** การทำนายคำถัดไป (Language Model แบบง่าย)
- **Game AI:** การตัดสินใจของ NPC

---

## 2. Counting Process (กระบวนการนับ)

### แนวคิดหลัก

Counting Process {N(t), t ≥ 0} คือกระบวนการสุ่มที่นับจำนวนเหตุการณ์ที่เกิดขึ้นจนถึงเวลา t

### คุณสมบัติ

1. **N(t) ≥ 0** สำหรับทุก t
2. **N(t) เป็นจำนวนเต็ม** (0, 1, 2, ...)
3. **ถ้า s < t แล้ว N(s) ≤ N(t)** (ไม่ลดลง — Non-decreasing)
4. **N(t) − N(s)** = จำนวนเหตุการณ์ที่เกิดในช่วง (s, t]

### ตัวอย่างที่เข้าใจง่าย

ลองนึกภาพว่าคุณนั่งอยู่หน้าร้านกาแฟแล้วนับจำนวนลูกค้าที่เดินเข้ามา:

```
เวลา (นาที):    0    5    8    12    15    20    25    30
ลูกค้าสะสม:     0    1    2     2     3     4     4     5
```

กราฟจะเป็น "ขั้นบันได" — ขึ้นครั้งละ 1 ขั้นทุกครั้งที่มีลูกค้าเข้า

### คุณสมบัติพิเศษ

**Independent Increments:** จำนวนเหตุการณ์ในช่วงเวลาที่ไม่ทับซ้อนกันเป็นอิสระต่อกัน
- N(10) − N(5) เป็นอิสระจาก N(5) − N(0)

**Stationary Increments:** การกระจายตัวของจำนวนเหตุการณ์ขึ้นอยู่กับความยาวของช่วงเวลาเท่านั้น ไม่ขึ้นกับจุดเริ่มต้น
- N(15) − N(10) มีการแจกแจงแบบเดียวกับ N(5) − N(0)

### การประยุกต์ใช้จริง

- **การควบคุมคุณภาพ:** นับจำนวนของเสียบนสายการผลิต
- **Reliability Engineering:** นับจำนวนครั้งที่เครื่องจักรเสีย
- **การจราจร:** นับจำนวนรถที่ผ่านจุดหนึ่ง
- **โทรคมนาคม:** นับจำนวนสายเรียกเข้า

---

## 3. Binomial Process (กระบวนการทวินาม)

### แนวคิดหลัก

Binomial Process เป็น Counting Process **ในเวลาแบบ Discrete** ที่ในแต่ละหน่วยเวลา เหตุการณ์จะเกิดขึ้น (success) ด้วยความน่าจะเป็น p หรือไม่เกิดขึ้น (failure) ด้วยความน่าจะเป็น 1 − p อย่างเป็นอิสระต่อกัน

### นิยามทางคณิตศาสตร์

ให้ X₁, X₂, X₃, ... เป็นลำดับของตัวแปรสุ่ม Bernoulli ที่เป็นอิสระกัน โดย P(Xᵢ = 1) = p

**Counting Process:**

$$N(n) = \sum_{i=1}^{n} X_i$$

โดย N(n) ~ Binomial(n, p)

**คุณสมบัติ:**
- E[N(n)] = np
- Var[N(n)] = np(1 − p)

### ตัวอย่าง 1: การตรวจสอบสินค้า

โรงงานผลิตชิ้นส่วนอิเล็กทรอนิกส์ ตรวจสอบทุกนาที (p = ความน่าจะเป็นที่ชิ้นส่วนจะเป็นของเสีย = 0.02)

**คำถาม:** ตรวจสอบ 100 ชิ้น ความน่าจะเป็นที่พบของเสีย ≤ 3 ชิ้น?

```
N(100) ~ Binomial(100, 0.02)

P(N ≤ 3) = P(0) + P(1) + P(2) + P(3)
         = C(100,0)(0.02)⁰(0.98)¹⁰⁰ + C(100,1)(0.02)¹(0.98)⁹⁹ 
           + C(100,2)(0.02)²(0.98)⁹⁸ + C(100,3)(0.02)³(0.98)⁹⁷
         ≈ 0.1326 + 0.2707 + 0.2734 + 0.1823
         ≈ 0.8590
```

### ตัวอย่าง 2: เกมทอยเหรียญ

ทอยเหรียญที่ยุติธรรม (p = 0.5) ทุกวินาที นับจำนวนหัว

```
วินาทีที่:    1    2    3    4    5    6    7    8    9    10
ผล:           H    T    H    H    T    H    T    T    H    H
N(t):         1    1    2    3    3    4    4    4    5    6
```

E[N(10)] = 10 × 0.5 = 5, ได้ 6 (สูงกว่าค่าคาดหวังเล็กน้อย)

### เวลาระหว่างเหตุการณ์ (Inter-arrival Time)

ถ้า T คือเวลาที่ต้องรอจนกว่า success แรกจะเกิด:

$$T \sim \text{Geometric}(p)$$

$$P(T = k) = (1-p)^{k-1} \cdot p, \quad k = 1, 2, 3, \ldots$$

$$E[T] = 1/p$$

### การประยุกต์ใช้จริง

- **การประกันภัย:** นับจำนวนลูกค้าที่เคลมในแต่ละวัน (แบบง่าย)
- **การแพทย์:** จำนวนผู้ป่วยที่ตอบสนองต่อยาจาก n คน
- **เครือข่ายคอมพิวเตอร์:** จำนวน packet ที่ส่งสำเร็จจาก n packet ที่ส่ง
- **การเกษตร:** จำนวนเมล็ดที่งอกจาก n เมล็ดที่ปลูก

---

## 4. Poisson Process (กระบวนการปัวซง)

### แนวคิดหลัก

Poisson Process เป็น Counting Process **ในเวลาแบบ Continuous** ที่เหตุการณ์เกิดขึ้นแบบสุ่มด้วยอัตราเฉลี่ย λ (lambda) ต่อหน่วยเวลา ถือเป็นกระบวนการที่สำคัญที่สุดตัวหนึ่งในทฤษฎีความน่าจะเป็น

### นิยามทางคณิตศาสตร์

{N(t), t ≥ 0} เป็น Poisson Process ด้วยอัตรา λ > 0 ถ้า:

1. N(0) = 0
2. มี **Independent Increments**
3. มี **Stationary Increments**
4. จำนวนเหตุการณ์ในช่วงเวลา t มีการแจกแจง Poisson:

$$P(N(t) = k) = \frac{(\lambda t)^k \cdot e^{-\lambda t}}{k!}, \quad k = 0, 1, 2, \ldots$$

**คุณสมบัติ:**
- E[N(t)] = λt
- Var[N(t)] = λt

### เวลาระหว่างเหตุการณ์ (Inter-arrival Time)

ถ้า Tᵢ คือเวลาระหว่างเหตุการณ์ที่ i−1 กับเหตุการณ์ที่ i:

$$T_i \sim \text{Exponential}(\lambda)$$

$$P(T_i > t) = e^{-\lambda t}$$

$$E[T_i] = 1/\lambda$$

นี่คือคุณสมบัติ **Memoryless** ของ Poisson Process — ไม่ว่าจะรอมานานเท่าไหร่ เวลาที่ต้องรอต่อก็ยังมีการแจกแจงแบบเดิม

### ตัวอย่าง 1: ลูกค้าเข้าร้าน

ลูกค้าเข้าร้านกาแฟเฉลี่ย 12 คนต่อชั่วโมง (λ = 12/ชม. = 0.2/นาที)

**คำถาม 1:** ความน่าจะเป็นที่จะมีลูกค้าเข้ามา ≥ 5 คน ใน 15 นาที?

```
λt = 12 × (15/60) = 3 คน (ค่าคาดหวัง)

P(N ≥ 5) = 1 − P(N ≤ 4)
         = 1 − [P(0) + P(1) + P(2) + P(3) + P(4)]
         = 1 − [e⁻³(1 + 3 + 4.5 + 4.5 + 3.375)]
         = 1 − e⁻³(16.375)
         = 1 − 0.0498 × 16.375
         ≈ 1 − 0.8153
         ≈ 0.1847
```

**คำถาม 2:** เวลาเฉลี่ยที่ต้องรอจนกว่าลูกค้าคนต่อไปจะเข้ามา?

```
E[T] = 1/λ = 1/12 ชั่วโมง = 5 นาที
```

### ตัวอย่าง 2: Server Requests

เซิร์ฟเวอร์ได้รับ request เฉลี่ย 100 ครั้งต่อวินาที (λ = 100)

**คำถาม:** ความน่าจะเป็นที่จะได้รับ request มากกว่า 120 ครั้งในวินาทีหนึ่ง?

```
N(1) ~ Poisson(100)

ใช้ Normal Approximation (เพราะ λ ใหญ่):
N ≈ Normal(μ = 100, σ² = 100)

P(N > 120) ≈ P(Z > (120 − 100)/10) = P(Z > 2) ≈ 0.0228
```

### คุณสมบัติพิเศษของ Poisson Process

**Superposition (การรวม):** ถ้ามี Poisson Process สองตัวที่เป็นอิสระกัน อัตรา λ₁ และ λ₂ การรวมกันก็ยังเป็น Poisson Process อัตรา λ₁ + λ₂

**Thinning/Decomposition (การแยก):** ถ้าแต่ละเหตุการณ์ใน Poisson Process อัตรา λ ถูกจัดประเภทเป็นชนิด I ด้วยความน่าจะเป็น p จะได้ Poisson Process ชนิด I อัตรา λp

**ตัวอย่าง Thinning:**
ลูกค้าเข้าร้าน 12 คน/ชม. โดย 40% เป็นลูกค้าขาประจำ
- ลูกค้าขาประจำ: Poisson(12 × 0.4 = 4.8 คน/ชม.)
- ลูกค้าขาจร: Poisson(12 × 0.6 = 7.2 คน/ชม.)

### การประยุกต์ใช้จริง

- **ทฤษฎีแถวคอย (Queueing Theory):** M/M/1, M/M/c queues — ใช้ออกแบบ call center, ห้องฉุกเฉิน
- **การประกันภัย:** จำลองจำนวนครั้งที่เกิดอุบัติเหตุ (Claim Arrival)
- **ฟิสิกส์:** การสลายกัมมันตรังสี (Radioactive Decay)
- **โทรคมนาคม:** การมาถึงของสายโทรศัพท์, packet data
- **การแพทย์:** จำนวนผู้ป่วยฉุกเฉินที่เข้าห้อง ER
- **การจราจร:** จำนวนรถที่ผ่านทางด่วนต่อนาที

---

## 5. ตารางเปรียบเทียบ

| คุณสมบัติ | Markov Process | Counting Process | Binomial Process | Poisson Process |
|-----------|---------------|-----------------|-----------------|----------------|
| **ประเภทเวลา** | Discrete หรือ Continuous | Continuous | Discrete | Continuous |
| **State Space** | ใดๆ ก็ได้ | จำนวนเต็มไม่ลบ | จำนวนเต็มไม่ลบ | จำนวนเต็มไม่ลบ |
| **คุณสมบัติหลัก** | Memoryless (Markov Property) | Non-decreasing, นับเหตุการณ์ | Bernoulli trials อิสระ | อัตราคงที่, Independent & Stationary Increments |
| **พารามิเตอร์** | Transition Matrix | ขึ้นอยู่กับชนิด | n (จำนวนครั้ง), p (ความน่าจะเป็น) | λ (อัตรา) |
| **การแจกแจง** | ขึ้นกับ Transition Matrix | ขึ้นกับชนิด | Binomial(n, p) | Poisson(λt) |
| **เวลาระหว่างเหตุการณ์** | ขึ้นกับโครงสร้าง | ขึ้นกับชนิด | Geometric(p) | Exponential(λ) |
| **ค่าคาดหวัง** | ขึ้นกับ Steady-State | ขึ้นกับชนิด | np | λt |
| **ความแปรปรวน** | ขึ้นกับโครงสร้าง | ขึ้นกับชนิด | np(1−p) | λt |

---

## 6. ความสัมพันธ์ระหว่างกระบวนการ

### ลำดับชั้น (Hierarchy)

```
         Counting Process (กรอบทั่วไปสุด — นับเหตุการณ์)
              /                    \
     Binomial Process          Poisson Process
     (Discrete Time)           (Continuous Time)
              \                    /
               \                  /
                → ทั้งสองเป็น Markov Process
```

### Binomial → Poisson (Poisson Limit Theorem)

เมื่อ n → ∞ และ p → 0 โดยที่ np = λ คงที่:

$$\text{Binomial}(n, p) \xrightarrow{d} \text{Poisson}(\lambda)$$

**ตัวอย่าง:** ถ้าโรงงานผลิตชิ้นส่วน 10,000 ชิ้น/วัน โดยแต่ละชิ้นมีโอกาสเป็นของเสีย 0.0003 สามารถประมาณด้วย Poisson(λ = 10000 × 0.0003 = 3)

### Poisson Process เป็น Continuous-Time Limit ของ Binomial Process

ถ้าแบ่งเวลา [0, t] เป็น n ช่วงเล็กๆ แล้วให้ p = λt/n:
เมื่อ n → ∞ Binomial Process จะลู่เข้าสู่ Poisson Process

### ทั้ง Binomial และ Poisson ต่างก็เป็น Markov Process

เพราะจำนวนเหตุการณ์ที่จะเกิดในอนาคตไม่ขึ้นกับจำนวนที่เกิดในอดีต (Independent Increments)

---

## 7. กรณีศึกษาเปรียบเทียบ: ระบบโรงพยาบาล

สมมติเราต้องวิเคราะห์ห้องฉุกเฉินของโรงพยาบาล:

### ใช้ Markov Process
วิเคราะห์การเปลี่ยนสถานะของเตียง: ว่าง → มีผู้ป่วย → กำลังทำความสะอาด → ว่าง
สร้าง Transition Matrix เพื่อหาว่าในระยะยาว เตียงจะว่างกี่เปอร์เซ็นต์ของเวลา

### ใช้ Counting Process
นับจำนวนผู้ป่วยที่เข้า ER สะสมตลอดทั้งวัน เพื่อดูแนวโน้มและ pattern

### ใช้ Binomial Process
ถ้าตรวจผู้ป่วยทุก 30 นาที (discrete time) แต่ละคนมีโอกาส 0.1 ที่ต้อง admit
ใน 20 คนที่ตรวจ จะ admit กี่คน? → Binomial(20, 0.1)

### ใช้ Poisson Process
ผู้ป่วยเข้า ER เฉลี่ย 8 คนต่อชั่วโมง (λ = 8) ต้องจัดเจ้าหน้าที่กี่คน?
คำนวณ P(N > 12) ในชั่วโมงใดๆ เพื่อเตรียมรับมือช่วงที่คนเยอะ

---

## 8. สรุป: เลือกใช้กระบวนการไหนเมื่อไหร่?

| สถานการณ์ | กระบวนการที่เหมาะสม | เหตุผล |
|-----------|-------------------|--------|
| วิเคราะห์การเปลี่ยนสถานะ (เช่น สุขภาพ, เครดิต) | Markov Process | สนใจว่าจะเปลี่ยนจากสถานะหนึ่งไปอีกสถานะ |
| นับเหตุการณ์โดยทั่วไป | Counting Process | กรอบงานทั่วไปสำหรับการนับ |
| นับ success จากการทดลองจำนวนจำกัด | Binomial Process | มีจำนวนครั้งแน่นอน, ผลแต่ละครั้งเป็นอิสระ |
| เหตุการณ์เกิดแบบสุ่มในเวลาต่อเนื่อง | Poisson Process | ไม่รู้จำนวนครั้งล่วงหน้า, สนใจอัตราการเกิด |
| ออกแบบระบบคิว (call center, ER) | Poisson Process | arrival rate คงที่, Memoryless |
| ทดสอบคุณภาพแบบ lot sampling | Binomial Process | ตรวจ n ชิ้น, นับของเสีย |
| พยากรณ์ลำดับเหตุการณ์ | Markov Process | อนาคตขึ้นกับปัจจุบันเท่านั้น |
| Rare event modeling | Poisson Process | เหตุการณ์เกิดน้อยแต่ตลอดเวลา |

---

*เอกสารนี้ครอบคลุมทฤษฎีพื้นฐานพร้อมตัวอย่างเชิงปฏิบัติ เหมาะสำหรับการเรียนรู้กระบวนการสุ่มในระดับมหาวิทยาลัย*